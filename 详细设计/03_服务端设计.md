# VoiceGrow 服务端设计

> 版本: v1.0
> 更新日期: 2026-01-20
> 文档类型: 服务端设计文档

---

## 1. 服务端概述

### 1.1 技术栈

| 组件 | 技术 | 版本 | 用途 |
|-----|-----|-----|-----|
| 运行时 | Python | 3.10+ | 服务端开发语言 |
| Web 框架 | FastAPI | 0.109+ | 异步 Web 框架 |
| ASGI 服务器 | Uvicorn | 0.27+ | 高性能异步服务器 |
| ASR 引擎 | faster-whisper | 1.0+ | 本地语音识别 |
| TTS 服务 | ai-manager TTS API | - | 外部 TTS 服务 (Google Cloud TTS) |
| LLM 服务 | ai-manager AI API | - | 外部 AI 服务 (多模型支持) |
| ORM | SQLAlchemy | 2.0+ | 数据库访问 |
| 异步 MySQL | aiomysql | 0.2+ | 异步数据库驱动 |
| 对象存储 | minio | 7.2+ | MinIO 客户端 |
| 异步 Redis | redis | 5.0+ | 缓存客户端 |

### 1.2 项目结构

```
server/
├── app/
│   ├── __init__.py
│   ├── main.py                 # 应用入口
│   ├── config.py               # 配置管理
│   │
│   ├── api/                    # API 层
│   │   ├── __init__.py
│   │   ├── websocket.py        # WebSocket 端点 (4399)
│   │   ├── http.py             # HTTP REST API (8000)
│   │   └── deps.py             # 依赖注入
│   │
│   ├── core/                   # 核心服务层
│   │   ├── __init__.py
│   │   ├── asr.py              # ASR 语音识别服务
│   │   ├── nlu.py              # NLU 意图识别服务
│   │   ├── tts.py              # TTS 语音合成服务
│   │   ├── llm.py              # LLM 对话服务
│   │   └── pipeline.py         # 语音处理流水线
│   │
│   ├── services/               # 业务服务层
│   │   ├── __init__.py
│   │   ├── content_service.py  # 内容服务
│   │   ├── minio_service.py    # MinIO 服务
│   │   └── session_service.py  # 会话服务
│   │
│   ├── handlers/               # 业务处理器
│   │   ├── __init__.py
│   │   ├── base.py             # Handler 基类
│   │   ├── story.py            # 故事处理器
│   │   ├── music.py            # 音乐处理器
│   │   ├── english.py          # 英语学习处理器
│   │   ├── chat.py             # 对话处理器
│   │   ├── control.py          # 播放控制处理器
│   │   └── registry.py         # Handler 注册表
│   │
│   ├── models/                 # 数据模型
│   │   ├── __init__.py
│   │   ├── database.py         # 数据库 ORM 模型
│   │   ├── protocol.py         # 协议消息模型
│   │   └── schemas.py          # Pydantic 模型
│   │
│   └── utils/                  # 工具类
│       ├── __init__.py
│       ├── audio.py            # 音频处理工具
│       └── logger.py           # 日志配置
│
├── tests/                      # 测试目录
│   ├── __init__.py
│   ├── test_asr.py
│   ├── test_nlu.py
│   └── test_handlers.py
│
├── Dockerfile                  # Docker 镜像
├── requirements.txt            # Python 依赖
└── pyproject.toml              # 项目配置
```

---

## 2. 配置管理

### 2.1 配置类设计

```python
# app/config.py

from dataclasses import dataclass, field
from typing import Optional
import os

@dataclass
class ServerConfig:
    """服务器配置"""
    host: str = "0.0.0.0"
    websocket_port: int = 4399
    http_port: int = 8000
    debug: bool = False

@dataclass
class ASRConfig:
    """ASR 配置"""
    model_size: str = "small"           # tiny, base, small, medium, large-v3
    device: str = "cpu"                 # cpu, cuda
    compute_type: str = "int8"          # float16, int8
    language: str = "zh"
    beam_size: int = 5
    vad_filter: bool = True

@dataclass
class TTSConfig:
    """TTS 配置 - 使用外部 ai-manager TTS API"""
    base_url: str = "http://ai-manager:8000"       # ai-manager 服务地址
    api_key: str = ""                              # API Key (ak_xxx)
    secret_key: str = ""                           # Secret Key (sk_xxx)
    voice_zh: str = "zh-CN-Neural2-C"              # 中文语音 (温和女声，适合儿童)
    voice_en: str = "en-US-Neural2-C"              # 英文语音
    speaking_rate: float = 0.9                     # 语速 (0.8-1.0 适合儿童)
    pitch: float = 0.0                             # 音调
    audio_format: str = "mp3"                      # 音频格式
    timeout: int = 30                              # 请求超时（秒）

@dataclass
class LLMConfig:
    """LLM 配置 - 使用外部 ai-manager AI API"""
    base_url: str = "http://ai-manager:8000"       # ai-manager 服务地址
    api_key: str = ""                              # API Key (ak_xxx)
    secret_key: str = ""                           # Secret Key (sk_xxx)
    model_preference: str = "gemini-2.0-flash-exp" # 首选模型 (可选)
    max_tokens: int = 300                          # 最大输出 token
    temperature: float = 0.7                       # 温度参数
    timeout: int = 30                              # 请求超时（秒）
    system_prompt: str = """你是一个儿童AI助手，名字叫"小声"。
请遵循以下规则：
1. 使用简单、易懂的语言
2. 回答要简短，适合语音播放（不超过100字）
3. 保持友好、温暖的语气
4. 不讨论任何不适合儿童的话题
5. 对于不确定的问题，诚实说"我不太确定"
6. 鼓励好奇心和学习"""

@dataclass
class MySQLConfig:
    """MySQL 配置"""
    host: str = "localhost"
    port: int = 3306
    user: str = "voicegrow"
    password: str = ""
    database: str = "voicegrow"

    @property
    def url(self) -> str:
        return f"mysql+aiomysql://{self.user}:{self.password}@{self.host}:{self.port}/{self.database}"

@dataclass
class MinIOConfig:
    """MinIO 配置"""
    endpoint: str = "localhost:9000"
    access_key: str = ""
    secret_key: str = ""
    bucket: str = "voicegrow"
    secure: bool = False

@dataclass
class RedisConfig:
    """Redis 配置"""
    host: str = "localhost"
    port: int = 6379
    password: Optional[str] = None
    db: int = 0

@dataclass
class AudioConfig:
    """音频配置"""
    sample_rate: int = 16000
    sample_width: int = 2               # 16-bit
    channels: int = 1
    silence_threshold: float = 0.5      # 静音判断阈值(秒)
    max_duration: float = 10.0          # 最大录音时长
    min_duration: float = 0.3           # 最小录音时长
    wake_timeout: float = 5.0           # 唤醒后等待说话超时

@dataclass
class AppConfig:
    """应用总配置"""
    server: ServerConfig = field(default_factory=ServerConfig)
    asr: ASRConfig = field(default_factory=ASRConfig)
    tts: TTSConfig = field(default_factory=TTSConfig)
    llm: LLMConfig = field(default_factory=LLMConfig)
    mysql: MySQLConfig = field(default_factory=MySQLConfig)
    minio: MinIOConfig = field(default_factory=MinIOConfig)
    redis: RedisConfig = field(default_factory=RedisConfig)
    audio: AudioConfig = field(default_factory=AudioConfig)

    @classmethod
    def from_env(cls) -> "AppConfig":
        """从环境变量加载配置"""
        return cls(
            server=ServerConfig(
                host=os.getenv("SERVER_HOST", "0.0.0.0"),
                websocket_port=int(os.getenv("WEBSOCKET_PORT", "4399")),
                http_port=int(os.getenv("HTTP_PORT", "8000")),
                debug=os.getenv("DEBUG", "false").lower() == "true",
            ),
            asr=ASRConfig(
                model_size=os.getenv("ASR_MODEL_SIZE", "small"),
                device=os.getenv("ASR_DEVICE", "cpu"),
                compute_type=os.getenv("ASR_COMPUTE_TYPE", "int8"),
                language=os.getenv("ASR_LANGUAGE", "zh"),
            ),
            tts=TTSConfig(
                base_url=os.getenv("TTS_BASE_URL", "http://ai-manager:8000"),
                api_key=os.getenv("TTS_API_KEY", ""),
                secret_key=os.getenv("TTS_SECRET_KEY", ""),
                voice_zh=os.getenv("TTS_VOICE_ZH", "zh-CN-Neural2-C"),
                voice_en=os.getenv("TTS_VOICE_EN", "en-US-Neural2-C"),
                speaking_rate=float(os.getenv("TTS_SPEAKING_RATE", "0.9")),
                timeout=int(os.getenv("TTS_TIMEOUT", "30")),
            ),
            llm=LLMConfig(
                base_url=os.getenv("LLM_BASE_URL", "http://ai-manager:8000"),
                api_key=os.getenv("LLM_API_KEY", ""),
                secret_key=os.getenv("LLM_SECRET_KEY", ""),
                model_preference=os.getenv("LLM_MODEL", "gemini-2.0-flash-exp"),
                max_tokens=int(os.getenv("LLM_MAX_TOKENS", "300")),
                temperature=float(os.getenv("LLM_TEMPERATURE", "0.7")),
                timeout=int(os.getenv("LLM_TIMEOUT", "30")),
            ),
            mysql=MySQLConfig(
                host=os.getenv("MYSQL_HOST", "localhost"),
                port=int(os.getenv("MYSQL_PORT", "3306")),
                user=os.getenv("MYSQL_USER", "voicegrow"),
                password=os.getenv("MYSQL_PASSWORD", ""),
                database=os.getenv("MYSQL_DATABASE", "voicegrow"),
            ),
            minio=MinIOConfig(
                endpoint=os.getenv("MINIO_ENDPOINT", "localhost:9000"),
                access_key=os.getenv("MINIO_ACCESS_KEY", ""),
                secret_key=os.getenv("MINIO_SECRET_KEY", ""),
                bucket=os.getenv("MINIO_BUCKET", "voicegrow"),
                secure=os.getenv("MINIO_SECURE", "false").lower() == "true",
            ),
            redis=RedisConfig(
                host=os.getenv("REDIS_HOST", "localhost"),
                port=int(os.getenv("REDIS_PORT", "6379")),
                password=os.getenv("REDIS_PASSWORD") or None,
                db=int(os.getenv("REDIS_DB", "0")),
            ),
        )

# 全局配置实例
config = AppConfig.from_env()
```

---

## 3. 核心服务设计

### 3.1 ASR 服务 (语音识别)

```python
# app/core/asr.py

from faster_whisper import WhisperModel
from dataclasses import dataclass, field
from typing import Optional
import numpy as np
import asyncio
import time

@dataclass
class AudioBuffer:
    """音频缓冲器 - 收集音频流直到检测到语音结束"""

    sample_rate: int = 16000
    sample_width: int = 2
    channels: int = 1

    # 缓冲区
    buffer: bytearray = field(default_factory=bytearray)

    # VAD 参数
    silence_threshold: float = 0.5
    max_duration: float = 10.0
    min_duration: float = 0.3

    # 状态
    is_recording: bool = False
    last_voice_time: float = 0.0
    start_time: float = 0.0

    def start(self):
        """开始录音"""
        self.buffer = bytearray()
        self.is_recording = True
        self.start_time = time.time()
        self.last_voice_time = time.time()

    def append(self, data: bytes):
        """追加音频数据"""
        if not self.is_recording:
            return

        self.buffer.extend(data)

        if self._has_voice_activity(data):
            self.last_voice_time = time.time()

    def should_stop(self) -> bool:
        """判断是否应该停止录音"""
        if not self.is_recording:
            return True

        elapsed = time.time() - self.start_time
        silence_duration = time.time() - self.last_voice_time

        if elapsed >= self.max_duration:
            return True

        if silence_duration >= self.silence_threshold and elapsed >= self.min_duration:
            return True

        return False

    def stop(self) -> bytes:
        """停止录音并返回音频数据"""
        self.is_recording = False
        return bytes(self.buffer)

    def _has_voice_activity(self, data: bytes) -> bool:
        """简单的语音活动检测"""
        if len(data) < 2:
            return False

        import struct
        samples = struct.unpack(f"<{len(data)//2}h", data)
        rms = (sum(s**2 for s in samples) / len(samples)) ** 0.5

        return rms > 500


class ASRService:
    """语音识别服务"""

    def __init__(self, config):
        self.config = config
        self.model: Optional[WhisperModel] = None
        self._semaphore = asyncio.Semaphore(3)  # 限制并发

    async def initialize(self):
        """初始化 Whisper 模型"""
        if self.model is None:
            self.model = WhisperModel(
                self.config.model_size,
                device=self.config.device,
                compute_type=self.config.compute_type
            )

    async def transcribe(self, audio_data: bytes, sample_rate: int = 16000) -> str:
        """转录音频数据"""
        async with self._semaphore:
            if self.model is None:
                await self.initialize()

            # 转换为 numpy 数组
            audio_array = np.frombuffer(audio_data, dtype=np.int16).astype(np.float32) / 32768.0

            # 重采样 (如果需要)
            if sample_rate != 16000:
                audio_array = self._resample(audio_array, sample_rate, 16000)

            # 执行识别
            segments, info = self.model.transcribe(
                audio_array,
                language=self.config.language,
                beam_size=self.config.beam_size,
                vad_filter=self.config.vad_filter,
            )

            text = "".join([segment.text for segment in segments])
            return text.strip()

    def _resample(self, audio: np.ndarray, orig_sr: int, target_sr: int) -> np.ndarray:
        """重采样音频"""
        try:
            import librosa
            return librosa.resample(audio, orig_sr=orig_sr, target_sr=target_sr)
        except ImportError:
            # 简单的线性插值重采样
            ratio = target_sr / orig_sr
            new_length = int(len(audio) * ratio)
            return np.interp(
                np.linspace(0, len(audio) - 1, new_length),
                np.arange(len(audio)),
                audio
            )
```

### 3.2 NLU 服务 (意图识别)

```python
# app/core/nlu.py

from enum import Enum
from dataclasses import dataclass
from typing import Optional, List, Tuple
import re

class Intent(Enum):
    """意图枚举"""
    # 故事
    PLAY_STORY = "play_story"
    PLAY_STORY_CATEGORY = "play_story_category"
    PLAY_STORY_BY_NAME = "play_story_by_name"

    # 音乐
    PLAY_MUSIC = "play_music"
    PLAY_MUSIC_CATEGORY = "play_music_category"
    PLAY_MUSIC_BY_NAME = "play_music_by_name"

    # 播放控制
    CONTROL_PAUSE = "control_pause"
    CONTROL_RESUME = "control_resume"
    CONTROL_STOP = "control_stop"
    CONTROL_NEXT = "control_next"
    CONTROL_PREVIOUS = "control_previous"
    CONTROL_VOLUME_UP = "control_volume_up"
    CONTROL_VOLUME_DOWN = "control_volume_down"

    # 英语学习
    ENGLISH_LEARN = "english_learn"
    ENGLISH_WORD = "english_word"
    ENGLISH_FOLLOW = "english_follow"

    # 对话
    CHAT = "chat"

    # 系统
    SYSTEM_TIME = "system_time"
    UNKNOWN = "unknown"


@dataclass
class NLUResult:
    """NLU 识别结果"""
    intent: Intent
    slots: dict
    confidence: float
    raw_text: str


class NLUService:
    """意图识别服务"""

    def __init__(self, llm_service=None):
        self.llm_service = llm_service
        self.rules = self._init_rules()
        self.category_mapping = self._init_category_mapping()

    def _init_rules(self) -> List[Tuple[str, Intent, dict]]:
        """初始化意图规则"""
        return [
            # 故事播放
            (r'(讲|说|播放|来)(一?个|点)?故事', Intent.PLAY_STORY, {}),
            (r'(我要|我想)?(听|播放)(.+)的?故事', Intent.PLAY_STORY_BY_NAME, {'story_name': 3}),
            (r'(播放|来点?|讲)(睡前|童话|寓言|科普|成语)故事', Intent.PLAY_STORY_CATEGORY, {'category': 2}),

            # 音乐播放
            (r'(播放|放|来)(一?首|点)?音乐', Intent.PLAY_MUSIC, {}),
            (r'(播放|放|来)(一?首|点)?歌', Intent.PLAY_MUSIC, {}),
            (r'(播放|放|来点?)(儿歌|摇篮曲|胎教音乐|古典音乐)', Intent.PLAY_MUSIC_CATEGORY, {'category': 2}),
            (r'(播放|放|来一?首)(.+)', Intent.PLAY_MUSIC_BY_NAME, {'music_name': 2}),

            # 播放控制
            (r'(暂停|停一?下|停止播放)', Intent.CONTROL_PAUSE, {}),
            (r'(继续|继续播放|播放)', Intent.CONTROL_RESUME, {}),
            (r'(停止|停|关闭)', Intent.CONTROL_STOP, {}),
            (r'(下一个|下一首|切歌|换一个)', Intent.CONTROL_NEXT, {}),
            (r'(上一个|上一首)', Intent.CONTROL_PREVIOUS, {}),
            (r'(大声点|音量大一点|声音大一点|调大)', Intent.CONTROL_VOLUME_UP, {}),
            (r'(小声点|音量小一点|声音小一点|调小)', Intent.CONTROL_VOLUME_DOWN, {}),

            # 英语学习
            (r'(学英语|英语学习|学习英语)', Intent.ENGLISH_LEARN, {}),
            (r'(.+)(用英语|英文)(怎么说|怎么读)', Intent.ENGLISH_WORD, {'word': 1}),
            (r'(跟我读|跟读)(.+)', Intent.ENGLISH_FOLLOW, {'word': 2}),

            # 系统
            (r'(现在)?几点(了|钟)?', Intent.SYSTEM_TIME, {}),
            (r'(什么)?时间', Intent.SYSTEM_TIME, {}),
        ]

    def _init_category_mapping(self) -> dict:
        """初始化分类映射"""
        return {
            '睡前': 'bedtime',
            '童话': 'fairy_tale',
            '寓言': 'fable',
            '科普': 'science',
            '成语': 'idiom',
            '儿歌': 'nursery_rhyme',
            '摇篮曲': 'lullaby',
            '胎教音乐': 'prenatal',
            '胎教': 'prenatal',
            '古典音乐': 'classical',
            '古典': 'classical',
        }

    async def recognize(self, text: str) -> NLUResult:
        """识别用户意图"""
        text = text.strip()

        # 规则匹配
        for pattern, intent, slot_mapping in self.rules:
            match = re.search(pattern, text)
            if match:
                slots = self._extract_slots(match, slot_mapping)
                return NLUResult(
                    intent=intent,
                    slots=slots,
                    confidence=0.9,
                    raw_text=text
                )

        # LLM 分类 (fallback)
        if self.llm_service:
            return await self._llm_classify(text)

        # 默认为对话意图
        return NLUResult(
            intent=Intent.CHAT,
            slots={},
            confidence=0.5,
            raw_text=text
        )

    def _extract_slots(self, match, slot_mapping: dict) -> dict:
        """提取槽位"""
        slots = {}
        for slot_name, group_idx in slot_mapping.items():
            if isinstance(group_idx, int) and group_idx <= len(match.groups()):
                value = match.group(group_idx)
                if value:
                    # 分类映射
                    if slot_name == 'category':
                        value = self.category_mapping.get(value, value)
                    slots[slot_name] = value
        return slots

    async def _llm_classify(self, text: str) -> NLUResult:
        """使用 LLM 进行意图分类"""
        # 简化版: 直接返回 CHAT
        return NLUResult(
            intent=Intent.CHAT,
            slots={},
            confidence=0.7,
            raw_text=text
        )
```

### 3.3 TTS 服务 (语音合成)

> 使用外部 **ai-manager TTS API** 服务，基于 Google Cloud Text-to-Speech，支持永久缓存和多账户轮换。

**服务特点**：
- **永久缓存**：相同文本只调用一次 Google TTS API，后续请求直接返回缓存
- **多账户轮换**：自动管理 Google TTS 配额，确保在免费额度内运行
- **公开 URL**：返回 MinIO URL，可直接播放，无需额外认证
- **SSML 支持**：支持停顿、强调、语速控制等高级语音合成功能

```python
# app/core/tts.py

import httpx
import hmac
import hashlib
import time
from typing import Optional
from dataclasses import dataclass
import logging

logger = logging.getLogger(__name__)

@dataclass
class TTSResult:
    """TTS 合成结果"""
    audio_url: str
    duration_ms: int
    character_count: int
    is_cached: bool
    voice_name: str
    language_code: str

class TTSService:
    """
    TTS 语音合成服务

    调用外部 ai-manager TTS API (基于 Google Cloud TTS)
    API 文档: F:\\develop\\jingen\\ai-manager\\docs\\api\\tts-synthesize.md
    """

    def __init__(self, config):
        self.config = config
        self._client: Optional[httpx.AsyncClient] = None

    async def _get_client(self) -> httpx.AsyncClient:
        """获取 HTTP 客户端"""
        if self._client is None:
            self._client = httpx.AsyncClient(
                base_url=self.config.base_url,
                timeout=self.config.timeout
            )
        return self._client

    def _generate_signature(self, method: str, path: str) -> tuple[str, str]:
        """
        生成 HMAC-SHA256 签名

        签名算法: HMAC-SHA256(SECRET_KEY, API_KEY + TIMESTAMP + HTTP_METHOD + PATH)
        """
        timestamp = str(int(time.time()))
        message = f"{self.config.api_key}{timestamp}{method.upper()}{path}"
        signature = hmac.new(
            self.config.secret_key.encode('utf-8'),
            message.encode('utf-8'),
            hashlib.sha256
        ).hexdigest()
        return timestamp, signature

    async def synthesize_to_url(
        self,
        text: str,
        language: str = "zh",
        speaking_rate: Optional[float] = None,
        pitch: Optional[float] = None,
        use_ssml: bool = False
    ) -> str:
        """
        合成语音并返回可直接播放的 URL

        Args:
            text: 要合成的文本 (或 SSML 内容)
            language: 语言 ("zh" 或 "en")
            speaking_rate: 语速 (0.25-4.0，默认使用配置值)
            pitch: 音调 (-20.0 到 20.0)
            use_ssml: 是否使用 SSML 格式

        Returns:
            音频文件的公开 URL (MinIO)
        """
        result = await self.synthesize(text, language, speaking_rate, pitch, use_ssml)
        return result.audio_url

    async def synthesize(
        self,
        text: str,
        language: str = "zh",
        speaking_rate: Optional[float] = None,
        pitch: Optional[float] = None,
        use_ssml: bool = False
    ) -> TTSResult:
        """
        合成语音，返回完整结果

        Returns:
            TTSResult 包含 audio_url, duration_ms, is_cached 等信息
        """
        # 确定语言代码和音色
        if language == "zh":
            language_code = "zh-CN"
            voice_name = self.config.voice_zh
        else:
            language_code = "en-US"
            voice_name = self.config.voice_en

        # 构建请求
        path = "/api/v1/tts/synthesize"
        timestamp, signature = self._generate_signature("POST", path)

        headers = {
            "Content-Type": "application/json",
            "X-API-Key": self.config.api_key,
            "X-Timestamp": timestamp,
            "X-Signature": signature
        }

        data = {
            "text": text,
            "language_code": language_code,
            "voice_name": voice_name,
            "speaking_rate": speaking_rate or self.config.speaking_rate,
            "pitch": pitch or self.config.pitch,
            "audio_format": self.config.audio_format
        }

        # SSML 模式
        if use_ssml:
            data["input_type"] = "ssml"

        # 发送请求
        client = await self._get_client()

        try:
            response = await client.post(path, headers=headers, json=data)
            response.raise_for_status()
            result = response.json()

            logger.info(
                f"TTS synthesized: {len(text)} chars, "
                f"cached={result.get('is_cached', False)}, "
                f"duration={result.get('duration_ms', 0)}ms"
            )

            return TTSResult(
                audio_url=result["audio_url"],
                duration_ms=result.get("duration_ms", 0),
                character_count=result.get("character_count", len(text)),
                is_cached=result.get("is_cached", False),
                voice_name=result.get("voice_name", voice_name),
                language_code=result.get("language_code", language_code)
            )

        except httpx.HTTPStatusError as e:
            if e.response.status_code == 429:
                logger.error("TTS quota exceeded - all accounts exhausted")
                raise Exception("语音服务暂时不可用，请稍后重试")
            else:
                logger.error(f"TTS API error: {e.response.status_code} - {e.response.text}")
                raise Exception(f"语音合成失败: {e.response.status_code}")

        except Exception as e:
            logger.error(f"TTS synthesis failed: {e}")
            raise

    async def synthesize_ssml(
        self,
        ssml: str,
        language: str = "zh"
    ) -> str:
        """
        使用 SSML 格式合成语音

        SSML 支持:
        - <speak> 根标签（必需）
        - <break time="500ms"/> 停顿
        - <emphasis level="strong">重点</emphasis> 强调
        - <prosody rate="slow">慢速</prosody> 语速控制

        示例:
            <speak>
                你好！<break time="300ms"/>
                <emphasis level="strong">欢迎</emphasis>来到声伴成长。
            </speak>
        """
        return await self.synthesize_to_url(ssml, language, use_ssml=True)

    async def synthesize_for_child(
        self,
        text: str,
        language: str = "zh"
    ) -> str:
        """
        儿童友好的语音合成

        - 语速略慢 (0.85)
        - 音调略高 (1.0)
        - 适合儿童收听
        """
        return await self.synthesize_to_url(
            text,
            language,
            speaking_rate=0.85,
            pitch=1.0
        )

    async def close(self):
        """关闭客户端"""
        if self._client:
            await self._client.aclose()
            self._client = None
        return os.path.join(self.config.cache_dir, language, f"{text_hash}.mp3")
```

### 3.4 LLM 服务 (对话服务)

> 使用外部 **ai-manager AI API** 服务，支持多模型自动选择、智能缓存和容错重试。

**服务特点**：
- **多模型支持**：Gemini、GPT-4、DeepSeek、Claude 等
- **智能缓存**：相同 prompt 直接返回缓存结果，零成本
- **自动容错**：模型失败时自动切换到备选模型
- **统一认证**：与 TTS 服务共享 API Key

```python
# app/core/llm.py

import httpx
import hmac
import hashlib
import time
from typing import Optional, List
from dataclasses import dataclass
import logging

logger = logging.getLogger(__name__)

@dataclass
class ChatMessage:
    role: str
    content: str

@dataclass
class LLMResult:
    """LLM 调用结果"""
    response: str
    model_used: str
    provider: str
    cached: bool
    prompt_tokens: int
    completion_tokens: int
    response_time_ms: float

class ContentFilter:
    """内容安全过滤器 (儿童内容)"""

    def __init__(self):
        # 敏感词模式 (实际使用时应加载外部配置)
        self.blocked_patterns = []

    def filter(self, text: str) -> tuple[bool, str]:
        """过滤内容"""
        import re

        for pattern in self.blocked_patterns:
            if re.search(pattern, text, re.IGNORECASE):
                return False, self._get_safe_response()

        # 长度限制 (适合语音播放)
        if len(text) > 500:
            text = text[:500] + "..."

        return True, text

    def _get_safe_response(self) -> str:
        import random
        responses = [
            "这个问题有点难，我们换一个话题吧",
            "我不太确定这个答案，要不我们聊点别的",
            "嗯...让我想想，我们先听个故事吧"
        ]
        return random.choice(responses)


class LLMService:
    """
    LLM 对话服务

    调用外部 ai-manager AI API (支持多模型)
    API 文档: F:\\develop\\jingen\\ai-manager\\docs\\api\\ai-services-prompt.md
    """

    def __init__(self, config):
        self.config = config
        self._client: Optional[httpx.AsyncClient] = None
        self.content_filter = ContentFilter()

    async def _get_client(self) -> httpx.AsyncClient:
        """获取 HTTP 客户端"""
        if self._client is None:
            self._client = httpx.AsyncClient(
                base_url=self.config.base_url,
                timeout=self.config.timeout
            )
        return self._client

    def _generate_signature(self, method: str, path: str) -> tuple[str, str]:
        """
        生成 HMAC-SHA256 签名

        签名算法: HMAC-SHA256(SECRET_KEY, API_KEY + TIMESTAMP + HTTP_METHOD + PATH)
        """
        timestamp = str(int(time.time()))
        message = f"{self.config.api_key}{timestamp}{method.upper()}{path}"
        signature = hmac.new(
            self.config.secret_key.encode('utf-8'),
            message.encode('utf-8'),
            hashlib.sha256
        ).hexdigest()
        return timestamp, signature

    async def chat(
        self,
        message: str,
        history: Optional[List[ChatMessage]] = None
    ) -> str:
        """
        对话 (简化接口，返回文本)

        Args:
            message: 用户消息
            history: 历史对话 (可选，用于上下文)

        Returns:
            AI 回复文本 (已过滤)
        """
        result = await self.chat_with_details(message, history)
        return result.response

    async def chat_with_details(
        self,
        message: str,
        history: Optional[List[ChatMessage]] = None
    ) -> LLMResult:
        """
        对话 (完整接口，返回详细结果)

        Returns:
            LLMResult 包含 response, model_used, cached 等信息
        """
        # 构建 prompt (包含历史上下文)
        prompt = message
        if history:
            # 取最近 5 轮对话作为上下文
            context_parts = []
            for msg in history[-10:]:
                prefix = "用户: " if msg.role == "user" else "助手: "
                context_parts.append(f"{prefix}{msg.content}")
            context = "\n".join(context_parts)
            prompt = f"对话历史:\n{context}\n\n当前用户问题: {message}"

        # 构建请求
        path = "/api/v1/ai-services/prompt"
        timestamp, signature = self._generate_signature("POST", path)

        headers = {
            "Content-Type": "application/json",
            "X-API-Key": self.config.api_key,
            "X-Timestamp": timestamp,
            "X-Signature": signature
        }

        data = {
            "prompt": prompt,
            "system_message": self.config.system_prompt,
            "temperature": self.config.temperature,
            "max_tokens": self.config.max_tokens,
        }

        # 指定首选模型 (可选)
        if self.config.model_preference:
            data["model_preference"] = self.config.model_preference

        # 发送请求
        client = await self._get_client()

        try:
            response = await client.post(path, headers=headers, json=data)
            response.raise_for_status()
            result = response.json()

            if not result.get("success"):
                raise Exception(result.get("error", "Unknown error"))

            data = result["data"]
            reply = data["response"]

            # 内容安全过滤
            is_safe, filtered_reply = self.content_filter.filter(reply)

            logger.info(
                f"LLM response: model={data.get('model_used')}, "
                f"cached={data.get('cached', False)}, "
                f"tokens={data.get('usage', {}).get('total_tokens', 0)}"
            )

            return LLMResult(
                response=filtered_reply,
                model_used=data.get("model_used", "unknown"),
                provider=data.get("provider_name", "unknown"),
                cached=data.get("cached", False),
                prompt_tokens=data.get("usage", {}).get("prompt_tokens", 0),
                completion_tokens=data.get("usage", {}).get("completion_tokens", 0),
                response_time_ms=data.get("response_time_ms", 0)
            )

        except httpx.HTTPStatusError as e:
            logger.error(f"LLM API error: {e.response.status_code} - {e.response.text}")
            return LLMResult(
                response="抱歉，我现在有点忙，稍后再试试吧",
                model_used="error",
                provider="error",
                cached=False,
                prompt_tokens=0,
                completion_tokens=0,
                response_time_ms=0
            )

        except Exception as e:
            logger.error(f"LLM chat failed: {e}")
            return LLMResult(
                response="抱歉，我现在有点忙，稍后再试试吧",
                model_used="error",
                provider="error",
                cached=False,
                prompt_tokens=0,
                completion_tokens=0,
                response_time_ms=0
            )

    async def close(self):
        """关闭客户端"""
        if self._client:
            await self._client.aclose()
            self._client = None
```

---

## 4. 业务处理器设计

### 4.1 Handler 基类

```python
# app/handlers/base.py

from abc import ABC, abstractmethod
from dataclasses import dataclass
from typing import Optional, Any

@dataclass
class HandlerRequest:
    """处理器请求"""
    intent: str
    slots: dict
    text: str
    session_id: str
    device_id: str
    context: dict

@dataclass
class HandlerResponse:
    """处理器响应"""
    text: str
    audio_url: Optional[str] = None
    action: Optional[str] = None
    context_update: Optional[dict] = None
    play_type: str = "tts"  # tts, content, both

class BaseHandler(ABC):
    """Handler 基类"""

    @abstractmethod
    async def handle(self, request: HandlerRequest) -> HandlerResponse:
        """处理请求"""
        pass

    @abstractmethod
    def can_handle(self, intent: str) -> bool:
        """判断是否能处理该意图"""
        pass
```

### 4.2 Handler 注册表

```python
# app/handlers/registry.py

from typing import Optional, List
from .base import BaseHandler, HandlerRequest, HandlerResponse

class HandlerRegistry:
    """Handler 注册表"""

    def __init__(self):
        self._handlers: List[BaseHandler] = []

    def register(self, handler: BaseHandler):
        """注册 Handler"""
        self._handlers.append(handler)

    def get_handler(self, intent: str) -> Optional[BaseHandler]:
        """获取 Handler"""
        for handler in self._handlers:
            if handler.can_handle(intent):
                return handler
        return None

    async def handle(self, request: HandlerRequest) -> HandlerResponse:
        """处理请求"""
        handler = self.get_handler(request.intent)

        if handler:
            return await handler.handle(request)

        return HandlerResponse(
            text="抱歉，我不太明白你的意思",
            play_type="tts"
        )
```

### 4.3 具体 Handler 实现

```python
# app/handlers/story.py

class StoryHandler(BaseHandler):
    """故事处理器"""

    def __init__(self, content_service):
        self.content_service = content_service
        self.handled_intents = [
            "play_story",
            "play_story_category",
            "play_story_by_name"
        ]

    def can_handle(self, intent: str) -> bool:
        return intent in self.handled_intents

    async def handle(self, request: HandlerRequest) -> HandlerResponse:
        intent = request.intent
        slots = request.slots

        content = None

        if intent == "play_story":
            content = await self.content_service.get_random(content_type="story")

        elif intent == "play_story_category":
            category = slots.get("category", "bedtime")
            content = await self.content_service.get_random(
                content_type="story",
                category=category
            )

        elif intent == "play_story_by_name":
            name = slots.get("story_name", "")
            results = await self.content_service.search(
                content_type="story",
                keyword=name,
                limit=1
            )
            if results:
                content = results[0]

        if content:
            return HandlerResponse(
                text=f"好的，现在为你播放《{content['title']}》",
                audio_url=content['audio_url'],
                play_type="both",
                context_update={
                    "current_content": content,
                    "content_type": "story"
                }
            )
        else:
            return HandlerResponse(
                text="抱歉，没有找到你想听的故事，换一个试试吧",
                play_type="tts"
            )


# app/handlers/control.py

class ControlHandler(BaseHandler):
    """播放控制处理器"""

    def __init__(self):
        self.handled_intents = [
            "control_pause",
            "control_resume",
            "control_stop",
            "control_next",
            "control_previous",
            "control_volume_up",
            "control_volume_down"
        ]

    def can_handle(self, intent: str) -> bool:
        return intent in self.handled_intents

    async def handle(self, request: HandlerRequest) -> HandlerResponse:
        action_map = {
            "control_pause": ("pause", "好的，已暂停"),
            "control_resume": ("play", "继续播放"),
            "control_stop": ("stop", "好的，已停止"),
            "control_next": ("next", "好的，下一个"),
            "control_previous": ("previous", "好的，上一个"),
            "control_volume_up": ("volume_up", "好的，音量调大了"),
            "control_volume_down": ("volume_down", "好的，音量调小了"),
        }

        action, text = action_map.get(request.intent, (None, "好的"))

        return HandlerResponse(
            text=text,
            action=action,
            play_type="tts"
        )
```

---

## 5. WebSocket 通信层设计

### 5.1 协议模型

```python
# app/models/protocol.py

from enum import Enum
from dataclasses import dataclass
from typing import Optional, Any
import uuid

class MessageType(Enum):
    REQUEST = "request"
    RESPONSE = "response"
    EVENT = "event"
    STREAM = "stream"

class PlayingState(Enum):
    PLAYING = "Playing"
    PAUSED = "Paused"
    IDLE = "Idle"

@dataclass
class Event:
    """客户端事件"""
    id: str
    event: str
    data: Optional[Any] = None

    @classmethod
    def parse(cls, data: dict) -> "Event":
        return cls(
            id=data.get("id", str(uuid.uuid4())),
            event=data["event"],
            data=data.get("data")
        )

@dataclass
class Request:
    """服务端请求"""
    id: str
    command: str
    payload: Optional[Any] = None

    def to_dict(self) -> dict:
        result = {"id": self.id, "command": self.command}
        if self.payload is not None:
            result["payload"] = self.payload
        return result

    @classmethod
    def create(cls, command: str, payload: Any = None) -> "Request":
        return cls(
            id=str(uuid.uuid4()),
            command=command,
            payload=payload
        )

@dataclass
class Response:
    """客户端响应"""
    id: str
    code: Optional[int] = None
    msg: Optional[str] = None
    data: Optional[Any] = None
```

### 5.2 连接管理器

```python
# app/api/websocket.py

import asyncio
import json
from dataclasses import dataclass, field
from typing import Dict, Optional, Any
from fastapi import WebSocket

@dataclass
class DeviceConnection:
    """设备连接"""
    device_id: str
    websocket: WebSocket
    context: dict = field(default_factory=dict)
    pending_responses: Dict[str, asyncio.Future] = field(default_factory=dict)

class ConnectionManager:
    """WebSocket 连接管理器"""

    def __init__(self):
        self.connections: Dict[str, DeviceConnection] = {}

    async def connect(self, websocket: WebSocket, device_id: str) -> DeviceConnection:
        await websocket.accept()

        conn = DeviceConnection(
            device_id=device_id,
            websocket=websocket
        )
        self.connections[device_id] = conn
        return conn

    async def disconnect(self, device_id: str):
        if device_id in self.connections:
            del self.connections[device_id]

    def get_connection(self, device_id: str) -> Optional[DeviceConnection]:
        return self.connections.get(device_id)

    async def send_request(
        self,
        device_id: str,
        command: str,
        payload: Any = None,
        wait_response: bool = False,
        timeout: float = 10.0
    ) -> Optional[dict]:
        """发送命令"""
        conn = self.connections.get(device_id)
        if not conn:
            raise Exception(f"Device {device_id} not connected")

        request_id = str(uuid.uuid4())
        request = {
            "id": request_id,
            "command": command
        }
        if payload is not None:
            request["payload"] = payload

        await conn.websocket.send_text(json.dumps(request))

        if wait_response:
            future = asyncio.get_event_loop().create_future()
            conn.pending_responses[request_id] = future

            try:
                return await asyncio.wait_for(future, timeout=timeout)
            finally:
                conn.pending_responses.pop(request_id, None)

        return None
```

### 5.3 语音流水线

```python
# app/core/pipeline.py

from enum import Enum
from .asr import ASRService, AudioBuffer
from .nlu import NLUService
from .tts import TTSService
from ..handlers.registry import HandlerRegistry
from ..handlers.base import HandlerRequest

class ListeningState(Enum):
    IDLE = "idle"
    WOKEN = "woken"
    LISTENING = "listening"
    PROCESSING = "processing"
    RESPONDING = "responding"

class VoicePipeline:
    """语音处理流水线"""

    def __init__(
        self,
        asr_service: ASRService,
        nlu_service: NLUService,
        tts_service: TTSService,
        handler_registry: HandlerRegistry,
        connection_manager
    ):
        self.asr = asr_service
        self.nlu = nlu_service
        self.tts = tts_service
        self.handlers = handler_registry
        self.conn_manager = connection_manager

    async def process_audio(self, device_id: str, audio_data: bytes):
        """处理完整音频"""
        conn = self.conn_manager.get_connection(device_id)
        if not conn:
            return

        try:
            # 1. ASR
            text = await self.asr.transcribe(audio_data)
            if not text:
                await self._respond_error(device_id, "抱歉，我没听清楚，请再说一次")
                return

            # 2. NLU
            nlu_result = await self.nlu.recognize(text)

            # 3. Handler
            request = HandlerRequest(
                intent=nlu_result.intent.value,
                slots=nlu_result.slots,
                text=text,
                session_id=device_id,
                device_id=device_id,
                context=conn.context
            )

            response = await self.handlers.handle(request)

            # 4. 更新上下文
            if response.context_update:
                conn.context.update(response.context_update)

            # 5. 执行响应
            await self._execute_response(device_id, response)

        except Exception as e:
            await self._respond_error(device_id, "抱歉，出了点问题，请稍后再试")

    async def _execute_response(self, device_id: str, response):
        """执行响应"""
        # 执行控制动作
        if response.action:
            await self.conn_manager.send_request(device_id, response.action)

        if response.play_type == "tts":
            await self._play_tts(device_id, response.text)

        elif response.play_type == "content":
            if response.audio_url:
                await self._play_url(device_id, response.audio_url)

        elif response.play_type == "both":
            await self._play_tts(device_id, response.text)
            if response.audio_url:
                await asyncio.sleep(0.5)
                await self._play_url(device_id, response.audio_url)

    async def _play_tts(self, device_id: str, text: str):
        """播放 TTS"""
        audio_url = await self.tts.synthesize_to_url(text)
        await self.conn_manager.send_request(
            device_id, "play_url", {"url": audio_url}
        )

    async def _play_url(self, device_id: str, url: str):
        """播放 URL"""
        await self.conn_manager.send_request(
            device_id, "play_url", {"url": url}
        )

    async def _respond_error(self, device_id: str, text: str):
        """响应错误"""
        await self._play_tts(device_id, text)
```

---

## 6. HTTP API 设计

```python
# app/api/http.py

from fastapi import APIRouter, Depends, HTTPException
from typing import List, Optional

router = APIRouter()

@router.get("/health")
async def health_check():
    """健康检查"""
    return {
        "status": "healthy",
        "version": "1.0.0"
    }

@router.get("/contents")
async def list_contents(
    type: Optional[str] = None,
    category: Optional[str] = None,
    keyword: Optional[str] = None,
    limit: int = 20,
    offset: int = 0
):
    """获取内容列表"""
    # 实现内容查询
    pass

@router.get("/contents/{content_id}")
async def get_content(content_id: int):
    """获取单个内容"""
    pass

@router.get("/english/words")
async def list_words(
    level: Optional[str] = None,
    category: Optional[str] = None,
    limit: int = 20
):
    """获取单词列表"""
    pass

@router.get("/devices")
async def list_devices():
    """获取在线设备"""
    pass

@router.post("/devices/{device_id}/command")
async def send_command(device_id: str, command: str, payload: dict = None):
    """发送命令到设备"""
    pass
```

---

## 7. 应用入口

```python
# app/main.py

from fastapi import FastAPI, WebSocket, WebSocketDisconnect
from contextlib import asynccontextmanager
import uvicorn

from .config import config
from .api.websocket import ConnectionManager
from .api.http import router as http_router
from .core.asr import ASRService
from .core.nlu import NLUService
from .core.tts import TTSService
from .core.llm import LLMService
from .core.pipeline import VoicePipeline
from .handlers.registry import HandlerRegistry
from .handlers.story import StoryHandler
from .handlers.control import ControlHandler
from .services.content_service import ContentService
from .services.minio_service import MinIOService

# 全局实例
connection_manager = ConnectionManager()
voice_pipeline: VoicePipeline = None

@asynccontextmanager
async def lifespan(app: FastAPI):
    """应用生命周期"""
    global voice_pipeline

    # 初始化服务
    minio_service = MinIOService(config.minio)
    content_service = ContentService(config.mysql, minio_service)

    asr_service = ASRService(config.asr)
    await asr_service.initialize()

    llm_service = LLMService(config.llm)
    nlu_service = NLUService(llm_service)
    tts_service = TTSService(config.tts, minio_service)

    # 注册 Handler
    handler_registry = HandlerRegistry()
    handler_registry.register(StoryHandler(content_service))
    handler_registry.register(ControlHandler())
    # ... 注册其他 Handler

    # 创建流水线
    voice_pipeline = VoicePipeline(
        asr_service=asr_service,
        nlu_service=nlu_service,
        tts_service=tts_service,
        handler_registry=handler_registry,
        connection_manager=connection_manager
    )

    yield

    # 清理资源

app = FastAPI(title="VoiceGrow", lifespan=lifespan)
app.include_router(http_router, prefix="/api")

@app.websocket("/")
async def websocket_endpoint(websocket: WebSocket):
    """WebSocket 端点"""
    device_id = websocket.query_params.get("device_id", "unknown")
    conn = await connection_manager.connect(websocket, device_id)

    try:
        while True:
            message = await websocket.receive()
            # 处理消息...

    except WebSocketDisconnect:
        pass
    finally:
        await connection_manager.disconnect(device_id)

if __name__ == "__main__":
    uvicorn.run(
        "app.main:app",
        host=config.server.host,
        port=config.server.websocket_port,
        reload=config.server.debug
    )
```

---

## 8. 错误处理与日志

### 8.1 日志配置

```python
# app/utils/logger.py

from loguru import logger
import sys

def setup_logger():
    logger.remove()
    logger.add(
        sys.stdout,
        format="<green>{time:YYYY-MM-DD HH:mm:ss}</green> | <level>{level: <8}</level> | <cyan>{name}</cyan>:<cyan>{function}</cyan>:<cyan>{line}</cyan> - <level>{message}</level>",
        level="INFO"
    )
    logger.add(
        "logs/voicegrow.log",
        rotation="10 MB",
        retention="7 days",
        level="DEBUG"
    )
```

### 8.2 异常处理

```python
# 全局异常处理
@app.exception_handler(Exception)
async def global_exception_handler(request, exc):
    logger.error(f"Unhandled exception: {exc}")
    return JSONResponse(
        status_code=500,
        content={"detail": "Internal server error"}
    )
```

---

## 附录: 依赖清单

```txt
# requirements.txt

# Web Framework
fastapi>=0.109.0
uvicorn[standard]>=0.27.0
websockets>=12.0

# Database
sqlalchemy[asyncio]>=2.0.25
aiomysql>=0.2.0

# Object Storage
minio>=7.2.3

# Redis
redis>=5.0.1

# ASR
faster-whisper>=1.0.0
numpy>=1.26.0

# TTS (调用外部 ai-manager API)
httpx>=0.27.0

# LLM (调用外部 ai-manager API，共用 httpx)

# Utilities
python-dotenv>=1.0.0
pydantic>=2.5.3
loguru>=0.7.2
aiofiles>=23.2.1

# Testing
pytest>=7.4.4
pytest-asyncio>=0.23.3
httpx>=0.26.0
```
